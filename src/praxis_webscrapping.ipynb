{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice web scraping\n",
    "As you've seen, scraping the internet is a skill that can get you all sorts of information. Here are some little challenges that you can try to gain more experience in the field:\n",
    "\n",
    "- Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'\n",
    "\n",
    "\n",
    "- Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'\n",
    "\n",
    "\n",
    "- Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'\n",
    "\n",
    "\n",
    "- Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "\n",
    "\n",
    "- List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'\n",
    "\n",
    "- A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'\n",
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_wiki = 'https://en.wikipedia.org/wiki/Python'\n",
    "response_wiki = req.get(url=url_wiki)\n",
    "soup_wiki = BeautifulSoup(response_wiki.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the URL: https://creativecommons.org/licenses/by-sa/3.0/\n",
      "Found the URL: https://en.wikipedia.org/wiki/Python\n",
      "Found the URL: https://en.wiktionary.org/wiki/Python\n",
      "Found the URL: https://en.wiktionary.org/wiki/python\n",
      "Found the URL: https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0\n",
      "Found the URL: https://en.wikipedia.org/w/index.php?title=Python&oldid=1048703433\n",
      "Found the URL: https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "Found the URL: https://www.wikidata.org/wiki/Special:EntityPage/Q747452\n",
      "Found the URL: https://commons.wikimedia.org/wiki/Category:Python\n",
      "Found the URL: https://af.wikipedia.org/wiki/Python\n",
      "Found the URL: https://als.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)\n",
      "Found the URL: https://az.wikipedia.org/wiki/Python\n",
      "Found the URL: https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)\n",
      "Found the URL: https://be.wikipedia.org/wiki/Python\n",
      "Found the URL: https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)\n",
      "Found the URL: https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)\n",
      "Found the URL: https://da.wikipedia.org/wiki/Python\n",
      "Found the URL: https://de.wikipedia.org/wiki/Python\n",
      "Found the URL: https://eo.wikipedia.org/wiki/Pitono_(apartigilo)\n",
      "Found the URL: https://eu.wikipedia.org/wiki/Python_(argipena)\n",
      "Found the URL: https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86\n",
      "Found the URL: https://fr.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0\n",
      "Found the URL: https://hr.wikipedia.org/wiki/Python_(razdvojba)\n",
      "Found the URL: https://io.wikipedia.org/wiki/Pitono\n",
      "Found the URL: https://id.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ia.wikipedia.org/wiki/Python_(disambiguation)\n",
      "Found the URL: https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)\n",
      "Found the URL: https://it.wikipedia.org/wiki/Python_(disambigua)\n",
      "Found the URL: https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F\n",
      "Found the URL: https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)\n",
      "Found the URL: https://kg.wikipedia.org/wiki/Mboma_(nyoka)\n",
      "Found the URL: https://la.wikipedia.org/wiki/Python_(discretiva)\n",
      "Found the URL: https://lb.wikipedia.org/wiki/Python\n",
      "Found the URL: https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)\n",
      "Found the URL: https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)\n",
      "Found the URL: https://nl.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3\n",
      "Found the URL: https://no.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://pl.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)\n",
      "Found the URL: https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)\n",
      "Found the URL: https://sk.wikipedia.org/wiki/Python\n",
      "Found the URL: https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)\n",
      "Found the URL: https://sh.wikipedia.org/wiki/Python\n",
      "Found the URL: https://fi.wikipedia.org/wiki/Python\n",
      "Found the URL: https://sv.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99\n",
      "Found the URL: https://tr.wikipedia.org/wiki/Python\n",
      "Found the URL: https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD\n",
      "Found the URL: https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86\n",
      "Found the URL: https://vi.wikipedia.org/wiki/Python\n",
      "Found the URL: https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)\n",
      "Found the URL: https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia\n",
      "Found the URL: https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "Found the URL: https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "Found the URL: https://stats.wikimedia.org/#/en.wikipedia.org\n",
      "Found the URL: https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "Found the URL: https://wikimediafoundation.org/\n",
      "Found the URL: https://www.mediawiki.org/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for a in soup_wiki.find_all(href=True):\n",
    "    if str(a['href']).startswith('http'):\n",
    "        print (\"Found the URL:\", a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_usa = 'http://uscode.house.gov/download/download.shtml'\n",
    "response_usa = req.get(url=url_usa)\n",
    "soup_usa = BeautifulSoup(response_usa.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = soup_usa.select('.usctitlechanged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 18 - Crimes and Criminal Procedure Ù­\n",
      "Title 34 - Crime Control and Law Enforcement\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fbi = 'https://www.fbi.gov/wanted/topten'\n",
    "response_fbi = req.get(url=url_fbi)\n",
    "soup_fbi = BeautifulSoup(response_fbi.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fbi = soup_fbi.select('.portal-type-person.castle-grid-block-item')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAFAEL CARO-QUINTERO\n",
      "YULAN ADONAY ARCHAGA CARIAS\n",
      "EUGENE PALMER\n",
      "BHADRESHKUMAR CHETANBHAI PATEL\n",
      "ALEJANDRO ROSALES CASTILLO\n",
      "ARNOLDO JIMENEZ\n",
      "JASON DEREK BROWN\n",
      "ALEXIS FLORES\n",
      "JOSE RODOLFO VILLARREAL-HERNANDEZ\n",
      "OCTAVIANO JUAREZ-CORRO\n"
     ]
    }
   ],
   "source": [
    "for i in res_fbi:\n",
    "    title = i.findAll(class_='title')[0]\n",
    "    print(title.text.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 4. Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_quake = 'https://www.emsc-csem.org/Earthquake/'\n",
    "response_quake = req.get(url=url_quake)\n",
    "soup_quake = BeautifulSoup(response_quake.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabel_head = soup_quake.select('#tbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time : tabev6 href\n",
    "- data : tabev6 href\n",
    "- lat : tabev1\n",
    "- long : tabev1\n",
    "- region : tb_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['20:42:27.532', '']\n",
      "['20:32:05.542', '']\n",
      "['20:31:11.843', '']\n",
      "['20:26:23.048', '']\n",
      "['20:07:50.51hr 07', '']\n",
      "['20:03:20.31hr 11', '']\n",
      "['20:00:26.31hr 14', '']\n",
      "['19:52:37.51hr 22', '']\n",
      "['19:52:37.11hr 22', '']\n",
      "['19:47:58.01hr 27', '']\n",
      "['19:47:07.01hr 27', '']\n",
      "['19:40:52.41hr 34', '']\n",
      "['19:39:26.01hr 35', '']\n",
      "['19:38:48.31hr 36', '']\n",
      "['19:37:15.01hr 37', '']\n",
      "['19:32:40.61hr 42', '']\n",
      "['19:20:07.91hr 54', '']\n",
      "['19:10:30.02hr 04', '']\n",
      "['19:09:57.32hr 05', '']\n",
      "['19:03:41.52hr 11', '']\n",
      "['18:57:14.02hr 17', '']\n",
      "['18:41:30.42hr 33', '']\n",
      "['18:27:29.22hr 47', '']\n",
      "['18:12:58.63hr 02', '']\n",
      "['17:13:16.44hr 01', '']\n",
      "['17:10:33.24hr 04', '']\n",
      "['16:49:50.04hr 25', '']\n",
      "['16:46:16.54hr 28', '']\n",
      "['16:38:21.14hr 36', '']\n",
      "['16:07:04.05hr 07', '']\n",
      "['15:58:25.85hr 16', '']\n",
      "['15:48:10.85hr 26', '']\n",
      "['15:44:13.25hr 30', '']\n",
      "['15:40:49.25hr 34', '']\n",
      "['15:37:57.95hr 37', '']\n",
      "['15:36:30.05hr 38', '']\n",
      "['15:34:27.35hr 40', '']\n",
      "['15:13:33.06hr 01', '']\n",
      "['15:13:11.66hr 01', '']\n",
      "['15:12:04.66hr 02', '']\n",
      "['14:54:39.76hr 20', '']\n",
      "['14:51:08.06hr 23', '']\n",
      "['14:38:09.06hr 36', '']\n",
      "['14:29:59.06hr 45', '']\n",
      "['14:26:45.56hr 48', '']\n",
      "['14:22:52.06hr 52', '']\n",
      "['14:18:30.76hr 56', '']\n",
      "['14:08:35.07hr 06', '']\n",
      "['14:07:30.07hr 07', '']\n",
      "['14:01:48.77hr 13', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(i.findAll(class_='tabev1')))\n",
    "date = i.findAll(class_='tabev6')\n",
    "for d in date:\n",
    "    date_raw = d.text.lstrip('earthquacke')\n",
    "    date_ = date_raw.split('\\xa0')\n",
    "    #print(date_[0])\n",
    "    print(date_[3].rsplit('min ago'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fbb94b493f4a2be40eeededea278266a31d2929b69a0d694da97e233e8112ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Enviroment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
